{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import json\n",
    "import shutil\n",
    "import argparse\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import read_gt_file, code_mask_to_labels, code_labels_to_colors, resize_image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [[random.randint(0, 255) for _ in range(3)] for _ in range(80)] \n",
    "classes = { \"ship\": 0, \"other\": 1, \"person\": 2, \"negative\": 3 }\n",
    "DATASET_PATH = '/data01/HiNAS-DATA/EO-DATA/RAW_DATA/mods/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interact로 Masked Image 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = read_gt_file(os.path.join(DATASET_PATH, 'mods.json'))\n",
    "num_sequences = gt[\"dataset\"][\"num_seq\"]\n",
    "\n",
    "from ipywidgets import interact\n",
    "\n",
    "@interact(seq_id=(1, num_sequences))\n",
    "def show_sample(seq_id=0):\n",
    "    fr_id = 0\n",
    "    \n",
    "    seq_path = gt['dataset']['sequences'][seq_id - 1]['path'][1:]\n",
    "    seq_path_split = seq_path.split('/')\n",
    "    \n",
    "    # Load image\n",
    "    img_name = gt['dataset']['sequences'][seq_id - 1]['frames'][fr_id]['image_file_name']\n",
    "    img_name_split = img_name.split('.')\n",
    "    \n",
    "    img = cv2.imread(os.path.join(DATASET_PATH, \"sequences\", seq_path, img_name))\n",
    "            \n",
    "    if img is None:\n",
    "        print('img is none')\n",
    "        return\n",
    "    \n",
    "    # Convert BGR TO RGB for visualization\n",
    "    # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Visualize image\n",
    "    obstacles = gt['dataset']['sequences'][seq_id - 1]['frames'][fr_id]['obstacles']\n",
    "    \n",
    "    # set rect_th for boxes\n",
    "    rect_th = max(round(sum(img.shape) / 2 * 0.001), 1)\n",
    "    # set text_th for category names\n",
    "    text_th = max(rect_th - 1, 1)\n",
    "    # set text_size for category names\n",
    "    text_size = rect_th / 3\n",
    "    \n",
    "    for obj in obstacles:\n",
    "        bbox = obj['bbox']\n",
    "        name = obj['type']\n",
    "        # BBOX given in Y_TL, X_TL, Y_BR, X_BR\n",
    "        x_min = bbox[0]\n",
    "        y_min = bbox[1]\n",
    "        x_max = bbox[2]\n",
    "        y_max = bbox[3]\n",
    "        \n",
    "        cv2.rectangle(img, \n",
    "                (x_min, y_min),\n",
    "                (x_max, y_max), \n",
    "                color=colors[classes[name]],\n",
    "                thickness=rect_th)\n",
    "        \n",
    "        p1, p2 = (int(x_min), int(y_min)), (int(x_max), int(y_max))\n",
    "        label = f\"{name}\"\n",
    "        w, h = cv2.getTextSize(label, 0, fontScale=text_size, thickness=text_th)[0]  # label width, height\n",
    "        outside = p1[1] - h - 3 >= 0  # label fits outside box\n",
    "        p2 = p1[0] + w, p1[1] - h - 3 if outside else p1[1] + h + 3\n",
    "        \n",
    "        cv2.rectangle(img, p1, p2, colors[classes[name]], -1, cv2.LINE_AA)  # filled\n",
    "        cv2.putText(\n",
    "            img,\n",
    "            label,\n",
    "            (p1[0], p1[1] - 2 if outside else p1[1] + h + 2),\n",
    "            0,\n",
    "            text_size,\n",
    "            (255, 255, 255),\n",
    "            thickness=text_th,\n",
    "        )\n",
    "        \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masked 이미지 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    export_video = False\n",
    "    # Create output folder for video export if it does not exist yet\n",
    "    if export_video:\n",
    "        pass\n",
    "        # os.makedirs(os.path.join(args.output_path, args.method), exist_ok=True)\n",
    "\n",
    "    # Read GT json\n",
    "    gt = read_gt_file(os.path.join(DATASET_PATH, 'mods.json'))\n",
    "\n",
    "    num_sequences = gt[\"dataset\"][\"num_seq\"]\n",
    "\n",
    "    for seq_id in range(num_sequences):\n",
    "        # Create folders if they dont exist yet\n",
    "        os.makedirs(os.path.join(\"results\", 'seq%02d' % seq_id, 'tmp_frames'), exist_ok=True)\n",
    "\n",
    "        num_frames_in_sequence = len(gt['dataset']['sequences'][seq_id - 1]['frames'])\n",
    "        \n",
    "        frame_counter = 0\n",
    "        for fr_id in range(num_frames_in_sequence):\n",
    "            sys.stdout.write(\"\\rProcessing sequence %02d, image %03d / %03d\\n\" %\n",
    "                                (seq_id, (fr_id + 1), num_frames_in_sequence))\n",
    "            \n",
    "            # feed, so it erases the previous line.\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            seq_path = gt['dataset']['sequences'][seq_id - 1]['path'][1:]\n",
    "            seq_path_split = seq_path.split('/')\n",
    "            \n",
    "            # Load image\n",
    "            img_name = gt['dataset']['sequences'][seq_id - 1]['frames'][fr_id]['image_file_name']\n",
    "            img_name_split = img_name.split('.')\n",
    "\n",
    "            img = cv2.imread(os.path.join(DATASET_PATH, \"sequences\", seq_path, img_name))\n",
    "            \n",
    "            if img is None:\n",
    "                print('img is none')\n",
    "                break\n",
    "            \n",
    "            # Convert BGR TO RGB for visualization\n",
    "            # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Visualize image\n",
    "            obstacles = gt['dataset']['sequences'][seq_id - 1]['frames'][fr_id]['obstacles']\n",
    "            \n",
    "            # set rect_th for boxes\n",
    "            rect_th = max(round(sum(img.shape) / 2 * 0.001), 1)\n",
    "            # set text_th for category names\n",
    "            text_th = max(rect_th - 1, 1)\n",
    "            # set text_size for category names\n",
    "            text_size = rect_th / 3\n",
    "            \n",
    "            for obj in obstacles:\n",
    "                bbox = obj['bbox']\n",
    "                name = obj['type']\n",
    "                # BBOX given in Y_TL, X_TL, Y_BR, X_BR\n",
    "                x_min = bbox[0]\n",
    "                y_min = bbox[1]\n",
    "                x_max = bbox[2]\n",
    "                y_max = bbox[3]\n",
    "                \n",
    "                cv2.rectangle(img, \n",
    "                      (x_min, y_min),\n",
    "                      (x_max, y_max), \n",
    "                      color=colors[classes[name]],\n",
    "                      thickness=rect_th)\n",
    "                \n",
    "                p1, p2 = (int(x_min), int(y_min)), (int(x_max), int(y_max))\n",
    "                label = f\"{name}\"\n",
    "                w, h = cv2.getTextSize(label, 0, fontScale=text_size, thickness=text_th)[0]  # label width, height\n",
    "                outside = p1[1] - h - 3 >= 0  # label fits outside box\n",
    "                p2 = p1[0] + w, p1[1] - h - 3 if outside else p1[1] + h + 3\n",
    "                \n",
    "                cv2.rectangle(img, p1, p2, colors[classes[name]], -1, cv2.LINE_AA)  # filled\n",
    "                cv2.putText(\n",
    "                    img,\n",
    "                    label,\n",
    "                    (p1[0], p1[1] - 2 if outside else p1[1] + h + 2),\n",
    "                    0,\n",
    "                    text_size,\n",
    "                    (255, 255, 255),\n",
    "                    thickness=text_th,\n",
    "                )\n",
    "                \n",
    "            cv2.imwrite(os.path.join(\"results\", 'seq%02d' % seq_id,\n",
    "                                            'tmp_frames', '%08d.png' % fr_id), img)\n",
    "            frame_counter += 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sahi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e1913e35ca0ac66adb58012caf442f6b034acfc1fbcae65ee49cbaddbd422c93"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
